[2022-11-17T16:05:44.720+0000] {processor.py:154} INFO - Started process (PID=1597) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:05:44.721+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:05:44.722+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:05:44.722+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:05:44.737+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:05:44.735+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:05:44.738+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:05:44.752+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.034 seconds
[2022-11-17T16:06:15.021+0000] {processor.py:154} INFO - Started process (PID=1626) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:06:15.025+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:06:15.027+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:06:15.027+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:06:15.056+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:06:15.042+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:06:15.061+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:06:15.101+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.087 seconds
[2022-11-17T16:06:56.202+0000] {processor.py:154} INFO - Started process (PID=1655) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:06:56.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:06:56.219+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:06:56.219+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:06:56.289+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:06:56.284+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:06:56.291+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:06:56.347+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.163 seconds
[2022-11-17T16:07:26.680+0000] {processor.py:154} INFO - Started process (PID=1684) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:07:26.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:07:26.686+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:07:26.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:07:26.699+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:07:26.697+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:07:26.700+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:07:26.722+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T16:07:57.033+0000] {processor.py:154} INFO - Started process (PID=1713) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:07:57.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:07:57.039+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:07:57.038+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:07:57.052+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:07:57.049+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:07:57.053+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:07:57.073+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:08:27.342+0000] {processor.py:154} INFO - Started process (PID=1742) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:08:27.345+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:08:27.346+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:08:27.346+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:08:27.360+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:08:27.357+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:08:27.362+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:08:27.381+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.044 seconds
[2022-11-17T16:08:57.605+0000] {processor.py:154} INFO - Started process (PID=1771) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:08:57.611+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:08:57.612+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:08:57.612+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:08:57.620+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:08:57.618+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:08:57.621+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:08:57.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.035 seconds
[2022-11-17T16:09:27.857+0000] {processor.py:154} INFO - Started process (PID=1792) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:09:27.859+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:09:27.860+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:09:27.860+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:09:27.868+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:09:27.866+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:09:27.869+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:09:27.884+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.030 seconds
[2022-11-17T16:09:58.189+0000] {processor.py:154} INFO - Started process (PID=1821) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:09:58.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:09:58.195+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:09:58.194+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:09:58.207+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:09:58.204+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:09:58.209+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:09:58.241+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.057 seconds
[2022-11-17T16:10:28.520+0000] {processor.py:154} INFO - Started process (PID=1849) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:10:28.523+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:10:28.526+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:10:28.526+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:10:28.539+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:10:28.536+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:10:28.541+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:10:28.562+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.046 seconds
[2022-11-17T16:10:58.789+0000] {processor.py:154} INFO - Started process (PID=1877) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:10:58.791+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:10:58.792+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:10:58.792+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:10:58.801+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:10:58.799+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:10:58.802+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:10:58.820+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.035 seconds
[2022-11-17T16:11:28.963+0000] {processor.py:154} INFO - Started process (PID=1898) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:11:28.966+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:11:28.967+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:11:28.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:11:28.976+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:11:28.973+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:11:28.977+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:11:28.991+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.030 seconds
[2022-11-17T16:11:59.157+0000] {processor.py:154} INFO - Started process (PID=1928) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:11:59.159+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:11:59.160+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:11:59.160+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:11:59.170+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:11:59.166+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:11:59.171+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:11:59.191+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T16:12:29.456+0000] {processor.py:154} INFO - Started process (PID=1957) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:12:29.459+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:12:29.461+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:12:29.461+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:12:29.472+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:12:29.469+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:12:29.473+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:12:29.495+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.043 seconds
[2022-11-17T16:12:59.777+0000] {processor.py:154} INFO - Started process (PID=1986) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:12:59.780+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:12:59.781+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:12:59.781+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:12:59.794+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:12:59.790+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:12:59.796+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:12:59.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:13:30.093+0000] {processor.py:154} INFO - Started process (PID=2006) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:13:30.096+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:13:30.098+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:13:30.097+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:13:30.109+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:13:30.107+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:13:30.111+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:13:30.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:14:00.460+0000] {processor.py:154} INFO - Started process (PID=2035) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:14:00.463+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:14:00.465+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:14:00.465+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:14:00.478+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:14:00.475+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:14:00.480+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:14:00.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T16:14:30.814+0000] {processor.py:154} INFO - Started process (PID=2064) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:14:30.817+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:14:30.819+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:14:30.819+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:14:30.830+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:14:30.828+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:14:30.832+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:14:30.849+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T16:15:01.196+0000] {processor.py:154} INFO - Started process (PID=2094) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:15:01.200+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:15:01.203+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:15:01.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:15:01.218+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:15:01.215+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:15:01.220+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:15:01.245+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.054 seconds
[2022-11-17T16:15:31.464+0000] {processor.py:154} INFO - Started process (PID=2124) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:15:31.466+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:15:31.467+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:15:31.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:15:31.475+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:15:31.473+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:15:31.476+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:15:31.492+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.031 seconds
[2022-11-17T16:16:01.844+0000] {processor.py:154} INFO - Started process (PID=2144) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:16:01.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:16:01.848+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:16:01.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:16:01.859+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:16:01.856+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:16:01.860+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:16:01.887+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:16:32.146+0000] {processor.py:154} INFO - Started process (PID=2173) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:16:32.149+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:16:32.150+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:16:32.150+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:16:32.158+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:16:32.156+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:16:32.159+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:16:32.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.033 seconds
[2022-11-17T16:17:02.276+0000] {processor.py:154} INFO - Started process (PID=2202) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:17:02.279+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:17:02.282+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:17:02.282+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:17:02.296+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:17:02.292+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:17:02.298+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:17:02.321+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.050 seconds
[2022-11-17T16:17:32.586+0000] {processor.py:154} INFO - Started process (PID=2231) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:17:32.588+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:17:32.590+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:17:32.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:17:32.601+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:17:32.598+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:17:32.605+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:17:32.627+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T16:18:02.900+0000] {processor.py:154} INFO - Started process (PID=2262) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:18:02.903+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:18:02.904+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:18:02.904+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:18:02.912+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:18:02.910+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:18:02.914+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:18:02.931+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.034 seconds
[2022-11-17T16:18:33.221+0000] {processor.py:154} INFO - Started process (PID=2282) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:18:33.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:18:33.225+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:18:33.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:18:33.235+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:18:33.233+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:18:33.237+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:18:33.257+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:19:03.524+0000] {processor.py:154} INFO - Started process (PID=2312) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:19:03.527+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:19:03.529+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:19:03.529+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:19:03.540+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:19:03.536+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:19:03.541+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:19:03.565+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T16:19:33.816+0000] {processor.py:154} INFO - Started process (PID=2341) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:19:33.819+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:19:33.820+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:19:33.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:19:33.832+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:19:33.830+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:19:33.835+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:19:33.854+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.043 seconds
[2022-11-17T16:20:04.131+0000] {processor.py:154} INFO - Started process (PID=2370) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:20:04.133+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:20:04.135+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:20:04.135+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:20:04.148+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:20:04.144+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:20:04.150+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:20:04.172+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.046 seconds
[2022-11-17T16:20:34.467+0000] {processor.py:154} INFO - Started process (PID=2398) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:20:34.469+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:20:34.470+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:20:34.470+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:20:34.481+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:20:34.478+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:20:34.482+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:20:34.501+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T16:21:04.809+0000] {processor.py:154} INFO - Started process (PID=2418) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:21:04.812+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:21:04.813+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:21:04.813+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:21:04.824+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:21:04.822+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:21:04.827+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:21:04.844+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T16:21:35.120+0000] {processor.py:154} INFO - Started process (PID=2447) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:21:35.124+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:21:35.126+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:21:35.126+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:21:35.142+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:21:35.137+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:21:35.144+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:21:35.168+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.052 seconds
[2022-11-17T16:22:05.477+0000] {processor.py:154} INFO - Started process (PID=2475) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:22:05.484+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:22:05.486+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:22:05.486+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:22:05.501+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:22:05.498+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:22:05.504+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:22:05.524+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.053 seconds
[2022-11-17T16:22:36.838+0000] {processor.py:154} INFO - Started process (PID=2502) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:22:36.855+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:22:36.904+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:22:36.903+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:22:36.950+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:22:36.938+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:22:36.962+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:22:37.031+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.211 seconds
[2022-11-17T16:23:07.422+0000] {processor.py:154} INFO - Started process (PID=2524) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:23:07.426+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:23:07.428+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:23:07.428+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:23:07.445+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:23:07.442+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:23:07.447+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:23:07.472+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.056 seconds
[2022-11-17T16:23:37.691+0000] {processor.py:154} INFO - Started process (PID=2553) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:23:37.694+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:23:37.696+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:23:37.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:23:37.706+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:23:37.703+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:23:37.707+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:23:37.726+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:24:07.998+0000] {processor.py:154} INFO - Started process (PID=2582) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:24:08.001+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:24:08.004+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:24:08.004+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:24:08.020+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:24:08.015+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:24:08.023+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:24:08.045+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.051 seconds
[2022-11-17T16:24:38.368+0000] {processor.py:154} INFO - Started process (PID=2609) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:24:38.371+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:24:38.372+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:24:38.372+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:24:38.380+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:24:38.378+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:24:38.381+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:24:38.396+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.031 seconds
[2022-11-17T16:25:08.697+0000] {processor.py:154} INFO - Started process (PID=2631) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:25:08.699+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:25:08.701+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:25:08.701+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:25:08.709+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:25:08.708+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:25:08.711+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:25:08.729+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.034 seconds
[2022-11-17T16:25:39.011+0000] {processor.py:154} INFO - Started process (PID=2660) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:25:39.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:25:39.015+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:25:39.015+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:25:39.026+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:25:39.023+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:25:39.029+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:25:39.047+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T16:26:09.373+0000] {processor.py:154} INFO - Started process (PID=2690) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:26:09.376+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:26:09.378+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:26:09.378+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:26:09.391+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:26:09.388+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:26:09.393+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:26:09.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.046 seconds
[2022-11-17T16:26:39.660+0000] {processor.py:154} INFO - Started process (PID=2719) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:26:39.664+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:26:39.665+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:26:39.665+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:26:39.677+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:26:39.674+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:26:39.678+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:26:39.696+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:27:09.787+0000] {processor.py:154} INFO - Started process (PID=2740) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:27:09.790+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:27:09.791+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:27:09.791+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:27:09.806+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:27:09.802+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:27:09.809+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:27:09.835+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.054 seconds
[2022-11-17T16:27:40.121+0000] {processor.py:154} INFO - Started process (PID=2770) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:27:40.124+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:27:40.126+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:27:40.126+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:27:40.140+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:27:40.137+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:27:40.141+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:27:40.188+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.073 seconds
[2022-11-17T16:28:10.486+0000] {processor.py:154} INFO - Started process (PID=2798) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:28:10.490+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:28:10.492+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:28:10.491+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:28:10.506+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:28:10.503+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:28:10.507+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:28:10.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.046 seconds
[2022-11-17T16:28:40.786+0000] {processor.py:154} INFO - Started process (PID=2826) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:28:40.789+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:28:40.790+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:28:40.790+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:28:40.801+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:28:40.799+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:28:40.802+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:28:40.820+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T16:29:11.050+0000] {processor.py:154} INFO - Started process (PID=2844) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:29:11.052+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:29:11.053+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:29:11.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:29:11.060+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:29:11.059+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:29:11.061+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:29:11.074+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.026 seconds
[2022-11-17T16:29:41.339+0000] {processor.py:154} INFO - Started process (PID=2873) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:29:41.341+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:29:41.342+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:29:41.342+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:29:41.351+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:29:41.349+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:29:41.352+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:29:41.369+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.033 seconds
[2022-11-17T16:30:11.639+0000] {processor.py:154} INFO - Started process (PID=2902) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:30:11.641+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:30:11.643+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:30:11.643+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:30:11.653+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:30:11.650+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:30:11.656+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:30:11.676+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.041 seconds
[2022-11-17T16:30:41.908+0000] {processor.py:154} INFO - Started process (PID=2931) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:30:41.910+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:30:41.912+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:30:41.912+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:30:41.926+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:30:41.923+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:30:41.927+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:30:41.950+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T16:31:12.171+0000] {processor.py:154} INFO - Started process (PID=2960) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:31:12.192+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:31:12.206+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:31:12.205+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:31:12.354+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:31:12.347+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:31:12.357+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:31:12.449+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.283 seconds
[2022-11-17T16:31:42.733+0000] {processor.py:154} INFO - Started process (PID=2980) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:31:42.737+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:31:42.739+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:31:42.739+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:31:42.753+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:31:42.749+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:31:42.756+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:31:42.776+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.048 seconds
[2022-11-17T16:32:13.256+0000] {processor.py:154} INFO - Started process (PID=3009) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:13.259+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:32:13.261+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:32:13.261+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:13.275+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:32:13.271+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 4, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2022-11-17T16:32:13.277+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:13.298+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:32:23.984+0000] {processor.py:154} INFO - Started process (PID=34) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:23.986+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:32:23.988+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:32:23.987+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:24.000+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:32:23.997+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:32:24.001+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:24.020+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T16:32:54.269+0000] {processor.py:154} INFO - Started process (PID=63) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:54.273+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:32:54.274+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:32:54.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:54.285+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:32:54.283+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:32:54.289+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:32:54.305+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T16:33:24.564+0000] {processor.py:154} INFO - Started process (PID=93) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:33:24.566+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:33:24.568+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:33:24.568+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:33:24.576+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:33:24.574+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:33:24.577+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:33:24.594+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.033 seconds
[2022-11-17T16:33:54.823+0000] {processor.py:154} INFO - Started process (PID=124) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:33:54.825+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:33:54.829+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:33:54.829+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:33:54.850+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:33:54.846+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:33:54.855+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:33:54.886+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.068 seconds
[2022-11-17T16:34:25.135+0000] {processor.py:154} INFO - Started process (PID=144) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:34:25.137+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:34:25.141+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:34:25.140+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:34:25.151+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:34:25.149+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:34:25.153+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:34:25.168+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T16:34:55.455+0000] {processor.py:154} INFO - Started process (PID=172) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:34:55.458+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:34:55.460+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:34:55.460+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:34:55.472+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:34:55.469+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:34:55.475+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:34:55.492+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.041 seconds
[2022-11-17T16:35:25.732+0000] {processor.py:154} INFO - Started process (PID=200) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:35:25.739+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:35:25.740+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:35:25.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:35:25.751+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:35:25.749+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:35:25.753+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:35:25.770+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.042 seconds
[2022-11-17T16:35:56.034+0000] {processor.py:154} INFO - Started process (PID=228) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:35:56.037+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:35:56.039+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:35:56.038+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:35:56.050+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:35:56.046+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:35:56.051+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:35:56.068+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T16:36:26.394+0000] {processor.py:154} INFO - Started process (PID=257) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:36:26.398+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:36:26.400+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:36:26.399+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:36:26.412+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:36:26.409+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:36:26.413+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:36:26.433+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.043 seconds
[2022-11-17T16:36:56.761+0000] {processor.py:154} INFO - Started process (PID=278) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:36:56.764+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:36:56.766+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:36:56.766+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:36:56.777+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:36:56.774+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:36:56.778+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:36:56.799+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.042 seconds
[2022-11-17T16:37:27.095+0000] {processor.py:154} INFO - Started process (PID=306) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:37:27.098+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:37:27.100+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:37:27.100+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:37:27.113+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:37:27.110+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:37:27.114+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:37:27.131+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T16:37:57.395+0000] {processor.py:154} INFO - Started process (PID=334) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:37:57.398+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:37:57.399+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:37:57.399+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:37:57.409+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:37:57.407+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:37:57.411+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:37:57.430+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:38:27.707+0000] {processor.py:154} INFO - Started process (PID=363) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:38:27.709+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:38:27.711+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:38:27.710+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:38:27.721+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:38:27.718+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:38:27.724+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:38:27.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.044 seconds
[2022-11-17T16:38:58.033+0000] {processor.py:154} INFO - Started process (PID=393) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:38:58.035+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:38:58.037+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:38:58.037+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:38:58.056+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:38:58.051+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:38:58.057+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:38:58.076+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.048 seconds
[2022-11-17T16:39:28.377+0000] {processor.py:154} INFO - Started process (PID=413) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:39:28.379+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:39:28.381+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:39:28.381+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:39:28.392+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:39:28.390+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:39:28.395+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:39:28.412+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:39:58.697+0000] {processor.py:154} INFO - Started process (PID=446) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:39:58.700+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:39:58.703+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:39:58.703+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:39:58.718+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:39:58.715+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:39:58.720+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:39:58.735+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:40:29.008+0000] {processor.py:154} INFO - Started process (PID=474) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:40:29.011+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:40:29.012+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:40:29.012+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:40:29.023+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:40:29.020+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:40:29.024+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:40:29.043+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.041 seconds
[2022-11-17T16:40:59.298+0000] {processor.py:154} INFO - Started process (PID=503) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:40:59.302+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:40:59.304+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:40:59.304+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:40:59.315+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:40:59.312+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:40:59.316+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:40:59.338+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.043 seconds
[2022-11-17T16:41:29.614+0000] {processor.py:154} INFO - Started process (PID=532) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:41:29.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:41:29.621+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:41:29.621+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:41:29.638+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:41:29.634+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:41:29.640+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:41:29.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:41:59.931+0000] {processor.py:154} INFO - Started process (PID=553) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:41:59.934+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:41:59.937+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:41:59.937+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:41:59.951+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:41:59.947+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:41:59.953+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:41:59.988+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.062 seconds
[2022-11-17T16:42:30.290+0000] {processor.py:154} INFO - Started process (PID=582) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:42:30.293+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:42:30.295+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:42:30.295+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:42:30.306+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:42:30.303+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:42:30.307+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:42:30.326+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T16:43:00.603+0000] {processor.py:154} INFO - Started process (PID=611) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:43:00.606+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:43:00.608+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:43:00.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:43:00.624+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:43:00.620+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:43:00.626+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:43:00.644+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.048 seconds
[2022-11-17T16:43:30.901+0000] {processor.py:154} INFO - Started process (PID=640) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:43:30.903+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:43:30.906+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:43:30.905+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:43:30.918+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:43:30.916+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:43:30.920+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:43:30.940+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.044 seconds
[2022-11-17T16:44:01.202+0000] {processor.py:154} INFO - Started process (PID=670) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:44:01.204+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:44:01.206+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:44:01.206+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:44:01.219+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:44:01.217+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:44:01.224+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:44:01.247+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.049 seconds
[2022-11-17T16:44:31.497+0000] {processor.py:154} INFO - Started process (PID=699) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:44:31.499+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:44:31.501+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:44:31.500+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:44:31.515+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:44:31.511+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:44:31.517+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:44:31.541+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:45:01.828+0000] {processor.py:154} INFO - Started process (PID=720) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:45:01.831+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:45:01.833+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:45:01.833+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:45:01.846+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:45:01.843+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:45:01.849+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:45:01.870+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.048 seconds
[2022-11-17T16:45:32.148+0000] {processor.py:154} INFO - Started process (PID=750) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:45:32.151+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:45:32.153+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:45:32.153+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:45:32.165+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:45:32.161+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:45:32.168+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:45:32.188+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T16:46:02.471+0000] {processor.py:154} INFO - Started process (PID=778) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:46:02.474+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:46:02.476+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:46:02.476+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:46:02.490+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:46:02.486+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:46:02.491+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:46:02.514+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.049 seconds
[2022-11-17T16:46:32.792+0000] {processor.py:154} INFO - Started process (PID=807) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:46:32.795+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:46:32.796+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:46:32.796+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:46:32.807+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:46:32.804+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:46:32.808+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:46:32.826+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T16:47:03.203+0000] {processor.py:154} INFO - Started process (PID=826) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:47:03.205+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:47:03.206+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:47:03.206+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:47:03.216+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:47:03.214+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:47:03.229+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:47:03.249+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.050 seconds
[2022-11-17T16:47:33.603+0000] {processor.py:154} INFO - Started process (PID=856) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:47:33.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:47:33.606+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:47:33.606+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:47:33.621+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:47:33.618+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:47:33.622+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:47:33.640+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:48:03.966+0000] {processor.py:154} INFO - Started process (PID=885) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:48:03.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:48:03.974+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:48:03.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:48:03.989+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:48:03.986+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:48:03.991+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:48:04.015+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.058 seconds
[2022-11-17T16:48:34.293+0000] {processor.py:154} INFO - Started process (PID=913) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:48:34.294+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:48:34.296+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:48:34.296+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:48:34.310+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:48:34.308+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:48:34.314+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:48:34.350+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.065 seconds
[2022-11-17T16:49:04.675+0000] {processor.py:154} INFO - Started process (PID=935) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:49:04.678+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:49:04.680+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:49:04.680+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:49:04.699+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:49:04.695+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:49:04.700+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:49:04.725+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.055 seconds
[2022-11-17T16:49:34.993+0000] {processor.py:154} INFO - Started process (PID=963) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:49:34.995+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:49:34.997+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:49:34.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:49:35.006+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:49:35.003+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:49:35.007+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:49:35.036+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.048 seconds
[2022-11-17T16:50:05.323+0000] {processor.py:154} INFO - Started process (PID=992) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:50:05.325+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:50:05.327+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:50:05.327+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:50:05.350+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:50:05.341+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:50:05.352+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:50:05.392+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.073 seconds
[2022-11-17T16:50:35.657+0000] {processor.py:154} INFO - Started process (PID=1020) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:50:35.659+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:50:35.661+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:50:35.661+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:50:35.671+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:50:35.668+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:50:35.673+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:50:35.692+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:51:06.000+0000] {processor.py:154} INFO - Started process (PID=1042) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:51:06.005+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:51:06.007+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:51:06.007+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:51:06.019+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:51:06.016+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:51:06.022+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:51:06.056+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.062 seconds
[2022-11-17T16:51:36.294+0000] {processor.py:154} INFO - Started process (PID=1072) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:51:36.296+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:51:36.297+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:51:36.297+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:51:36.307+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:51:36.305+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:51:36.308+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:51:36.329+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T16:52:06.623+0000] {processor.py:154} INFO - Started process (PID=1101) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:52:06.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:52:06.628+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:52:06.628+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:52:06.640+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:52:06.636+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:52:06.641+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:52:06.669+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.053 seconds
[2022-11-17T16:52:37.053+0000] {processor.py:154} INFO - Started process (PID=1130) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:52:37.057+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:52:37.060+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:52:37.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:52:37.073+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:52:37.071+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:52:37.075+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:52:37.104+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.056 seconds
[2022-11-17T16:53:07.386+0000] {processor.py:154} INFO - Started process (PID=1150) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:53:07.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:53:07.389+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:53:07.389+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:53:07.399+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:53:07.397+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:53:07.400+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:53:07.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T16:53:37.662+0000] {processor.py:154} INFO - Started process (PID=1179) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:53:37.665+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:53:37.666+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:53:37.666+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:53:37.675+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:53:37.673+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:53:37.676+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:53:37.694+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.034 seconds
[2022-11-17T16:54:07.884+0000] {processor.py:154} INFO - Started process (PID=1209) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:54:07.886+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:54:07.887+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:54:07.887+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:54:07.911+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:54:07.907+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:54:07.914+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:54:07.953+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.074 seconds
[2022-11-17T16:54:38.199+0000] {processor.py:154} INFO - Started process (PID=1239) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:54:38.201+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:54:38.203+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:54:38.203+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:54:38.219+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:54:38.215+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:54:38.221+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:54:38.241+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T16:55:08.498+0000] {processor.py:154} INFO - Started process (PID=1259) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:55:08.500+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:55:08.502+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:55:08.502+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:55:08.515+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:55:08.510+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:55:08.519+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:55:08.540+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T16:55:38.769+0000] {processor.py:154} INFO - Started process (PID=1289) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:55:38.771+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:55:38.773+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:55:38.773+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:55:38.784+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:55:38.781+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:55:38.786+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:55:38.805+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T16:56:09.049+0000] {processor.py:154} INFO - Started process (PID=1318) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:56:09.051+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:56:09.053+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:56:09.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:56:09.063+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:56:09.060+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:56:09.065+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:56:09.082+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T16:56:39.400+0000] {processor.py:154} INFO - Started process (PID=1347) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:56:39.404+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:56:39.406+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:56:39.406+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:56:39.417+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:56:39.414+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:56:39.418+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:56:39.435+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:57:09.744+0000] {processor.py:154} INFO - Started process (PID=1376) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:57:09.747+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:57:09.748+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:57:09.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:57:09.759+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:57:09.756+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:57:09.760+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:57:09.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T16:57:40.109+0000] {processor.py:154} INFO - Started process (PID=1396) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:57:40.110+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:57:40.111+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:57:40.111+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:57:40.119+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:57:40.117+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:57:40.121+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:57:40.134+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.028 seconds
[2022-11-17T16:58:10.417+0000] {processor.py:154} INFO - Started process (PID=1424) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:58:10.419+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:58:10.420+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:58:10.420+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:58:10.430+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:58:10.429+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:58:10.432+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:58:10.450+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T16:58:40.746+0000] {processor.py:154} INFO - Started process (PID=1453) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:58:40.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:58:40.750+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:58:40.749+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:58:40.762+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:58:40.759+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:58:40.765+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:58:40.782+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T16:59:11.085+0000] {processor.py:154} INFO - Started process (PID=1482) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:59:11.087+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:59:11.088+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:59:11.088+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:59:11.098+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:59:11.096+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:59:11.099+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:59:11.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.032 seconds
[2022-11-17T16:59:41.337+0000] {processor.py:154} INFO - Started process (PID=1510) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:59:41.338+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T16:59:41.339+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:59:41.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:59:41.348+0000] {logging_mixin.py:137} INFO - [2022-11-17T16:59:41.346+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T16:59:41.350+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T16:59:41.365+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.031 seconds
[2022-11-17T17:00:11.683+0000] {processor.py:154} INFO - Started process (PID=1531) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:00:11.685+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:00:11.686+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:00:11.686+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:00:11.696+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:00:11.693+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:00:11.697+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:00:11.717+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.036 seconds
[2022-11-17T17:00:41.939+0000] {processor.py:154} INFO - Started process (PID=1561) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:00:41.941+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:00:41.943+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:00:41.943+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:00:41.951+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:00:41.949+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:00:41.953+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:00:41.972+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.035 seconds
[2022-11-17T17:01:12.211+0000] {processor.py:154} INFO - Started process (PID=1590) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:01:12.221+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:01:12.224+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:01:12.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:01:12.250+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:01:12.245+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:01:12.254+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:01:12.286+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.100 seconds
[2022-11-17T17:01:42.463+0000] {processor.py:154} INFO - Started process (PID=1619) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:01:42.465+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:01:42.467+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:01:42.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:01:42.476+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:01:42.474+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:01:42.478+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:01:42.495+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.035 seconds
[2022-11-17T17:02:12.766+0000] {processor.py:154} INFO - Started process (PID=1646) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:02:12.771+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:02:12.785+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:02:12.785+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:02:12.824+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:02:12.811+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:02:12.826+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:02:12.897+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.136 seconds
[2022-11-17T17:02:31.123+0000] {processor.py:154} INFO - Started process (PID=34) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:02:31.126+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:02:31.128+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:02:31.128+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:02:31.140+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:02:31.136+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:02:31.142+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:02:31.161+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T17:03:01.360+0000] {processor.py:154} INFO - Started process (PID=63) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:03:01.363+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:03:01.365+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:03:01.364+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:03:01.376+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:03:01.373+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:03:01.378+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:03:01.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.043 seconds
[2022-11-17T17:03:31.617+0000] {processor.py:154} INFO - Started process (PID=92) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:03:31.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:03:31.626+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:03:31.625+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:03:31.644+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:03:31.639+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:03:31.646+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:03:31.663+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.051 seconds
[2022-11-17T17:04:01.931+0000] {processor.py:154} INFO - Started process (PID=112) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:04:01.933+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:04:01.935+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:04:01.935+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:04:01.948+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:04:01.945+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:04:01.950+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:04:01.967+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.039 seconds
[2022-11-17T17:04:32.265+0000] {processor.py:154} INFO - Started process (PID=141) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:04:32.267+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:04:32.269+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:04:32.269+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:04:32.282+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:04:32.279+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:04:32.285+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:04:32.308+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T17:05:02.611+0000] {processor.py:154} INFO - Started process (PID=171) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:05:02.615+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:05:02.618+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:05:02.618+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:05:02.651+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:05:02.644+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:05:02.655+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:05:02.683+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.076 seconds
[2022-11-17T17:05:32.939+0000] {processor.py:154} INFO - Started process (PID=200) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:05:32.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:05:32.942+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:05:32.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:05:32.951+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:05:32.949+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:05:32.953+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:05:32.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T17:06:03.199+0000] {processor.py:154} INFO - Started process (PID=228) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:06:03.200+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:06:03.201+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:06:03.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:06:03.213+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:06:03.211+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:06:03.214+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:06:03.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.037 seconds
[2022-11-17T17:06:33.501+0000] {processor.py:154} INFO - Started process (PID=248) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:06:33.505+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:06:33.509+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:06:33.509+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:06:33.529+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:06:33.526+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:06:33.531+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:06:33.550+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.053 seconds
[2022-11-17T17:07:03.801+0000] {processor.py:154} INFO - Started process (PID=278) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:07:03.803+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:07:03.805+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:07:03.805+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:07:03.819+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:07:03.816+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:07:03.821+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:07:03.846+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.049 seconds
[2022-11-17T17:07:34.224+0000] {processor.py:154} INFO - Started process (PID=306) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:07:34.226+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:07:34.231+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:07:34.231+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:07:34.246+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:07:34.243+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:07:34.250+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:07:34.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.053 seconds
[2022-11-17T17:08:04.565+0000] {processor.py:154} INFO - Started process (PID=334) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:08:04.576+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:08:04.580+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:08:04.580+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:08:04.595+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:08:04.591+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:08:04.596+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:08:04.616+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.057 seconds
[2022-11-17T17:08:34.848+0000] {processor.py:154} INFO - Started process (PID=363) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:08:34.850+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:08:34.851+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:08:34.851+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:08:34.857+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:08:34.856+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:08:34.859+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:08:34.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.027 seconds
[2022-11-17T17:09:05.113+0000] {processor.py:154} INFO - Started process (PID=383) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:09:05.116+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:09:05.118+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:09:05.117+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:09:05.138+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:09:05.135+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:09:05.139+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:09:05.159+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.050 seconds
[2022-11-17T17:09:35.398+0000] {processor.py:154} INFO - Started process (PID=412) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:09:35.401+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:09:35.402+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:09:35.402+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:09:35.413+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:09:35.411+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:09:35.416+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:09:35.431+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T17:10:05.673+0000] {processor.py:154} INFO - Started process (PID=441) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:10:05.676+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:10:05.678+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:10:05.678+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:10:05.691+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:10:05.688+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:10:05.692+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:10:05.711+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.044 seconds
[2022-11-17T17:10:35.958+0000] {processor.py:154} INFO - Started process (PID=470) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:10:35.960+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:10:35.965+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:10:35.965+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:10:35.978+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:10:35.975+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:10:35.980+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:10:36.000+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.045 seconds
[2022-11-17T17:11:06.289+0000] {processor.py:154} INFO - Started process (PID=499) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:11:06.291+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:11:06.292+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:11:06.292+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:11:06.302+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:11:06.300+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:11:06.303+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:11:06.326+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T17:11:36.623+0000] {processor.py:154} INFO - Started process (PID=518) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:11:36.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:11:36.627+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:11:36.627+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:11:36.641+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:11:36.637+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:11:36.643+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:11:36.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.041 seconds
[2022-11-17T17:12:06.927+0000] {processor.py:154} INFO - Started process (PID=548) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:12:06.929+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:12:06.930+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:12:06.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:12:06.951+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:12:06.947+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:12:06.954+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:12:06.977+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.054 seconds
[2022-11-17T17:12:37.314+0000] {processor.py:154} INFO - Started process (PID=579) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:12:37.317+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:12:37.319+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:12:37.319+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:12:37.334+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:12:37.330+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:12:37.335+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:12:37.361+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.053 seconds
[2022-11-17T17:13:07.657+0000] {processor.py:154} INFO - Started process (PID=608) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:13:07.659+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:13:07.662+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:13:07.662+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:13:07.676+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:13:07.672+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:13:07.680+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:13:07.698+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.047 seconds
[2022-11-17T17:13:37.938+0000] {processor.py:154} INFO - Started process (PID=637) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:13:37.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:13:37.941+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:13:37.941+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:13:37.950+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:13:37.948+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:13:37.951+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:13:37.969+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.034 seconds
[2022-11-17T17:14:08.257+0000] {processor.py:154} INFO - Started process (PID=657) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:14:08.262+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:14:08.266+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:14:08.266+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:14:08.279+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:14:08.276+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:14:08.283+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:14:08.299+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.048 seconds
[2022-11-17T17:14:38.595+0000] {processor.py:154} INFO - Started process (PID=686) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:14:38.597+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:14:38.599+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:14:38.599+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:14:38.616+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:14:38.611+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:14:38.618+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:14:38.639+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.050 seconds
[2022-11-17T17:16:24.162+0000] {processor.py:154} INFO - Started process (PID=782) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:16:24.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:16:24.165+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:16:24.165+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:16:24.182+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:16:24.179+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:16:24.183+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:16:24.206+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.046 seconds
[2022-11-17T17:22:32.166+0000] {processor.py:154} INFO - Started process (PID=1092) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:22:32.168+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:22:32.169+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:22:32.169+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:22:32.185+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:22:32.183+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:22:32.186+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:22:32.207+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.043 seconds
[2022-11-17T17:23:02.728+0000] {processor.py:154} INFO - Started process (PID=1123) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:02.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:23:02.732+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:02.732+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:02.748+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:02.745+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:23:02.749+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:02.768+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.043 seconds
[2022-11-17T17:23:14.883+0000] {processor.py:154} INFO - Started process (PID=1133) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:14.885+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:23:14.887+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:14.887+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:14.903+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:14.901+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:23:14.904+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:14.918+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.038 seconds
[2022-11-17T17:23:15.969+0000] {processor.py:154} INFO - Started process (PID=1135) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:15.971+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:23:15.973+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:15.973+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:16.000+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:15.998+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:23:16.003+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:16.020+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.055 seconds
[2022-11-17T17:23:40.256+0000] {processor.py:154} INFO - Started process (PID=1164) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:40.258+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:23:40.259+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:40.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:40.274+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:23:40.273+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:23:40.276+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:23:40.289+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.036 seconds
[2022-11-17T17:24:10.678+0000] {processor.py:154} INFO - Started process (PID=1185) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:10.681+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:24:10.683+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:10.682+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:10.695+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:10.692+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:24:10.696+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:10.714+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.040 seconds
[2022-11-17T17:24:39.029+0000] {processor.py:154} INFO - Started process (PID=1214) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:39.032+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:24:39.033+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:39.033+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:39.058+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:39.055+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/load_data_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 159, in init
    py4j = glob(os.path.join(spark_python, "lib", "py4j-*.zip"))[0]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data_to_spark.py", line 5, in <module>
    findspark.init()
  File "/home/airflow/.local/lib/python3.7/site-packages/findspark.py", line 163, in init
    spark_python
Exception: Unable to find py4j in /opt/homebrew/Cellar/apache-spark/3.3.1/libexec/python, your SPARK_HOME may not be configured correctly
[2022-11-17T17:24:39.060+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:39.077+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.052 seconds
[2022-11-17T17:24:54.271+0000] {processor.py:154} INFO - Started process (PID=1226) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:54.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:24:54.276+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:54.276+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:54.321+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:24:54.397+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:54.397+0000] {manager.py:507} INFO - Created Permission View: can read on DAG:python_operator
[2022-11-17T17:24:54.404+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:54.404+0000] {manager.py:507} INFO - Created Permission View: can edit on DAG:python_operator
[2022-11-17T17:24:54.407+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:54.407+0000] {manager.py:507} INFO - Created Permission View: can delete on DAG:python_operator
[2022-11-17T17:24:54.408+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:54.408+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:24:54.417+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:54.417+0000] {dag.py:2606} INFO - Creating ORM DAG for python_operator
[2022-11-17T17:24:54.425+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:24:54.424+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-16T00:00:00+00:00, run_after=2022-11-17T00:00:00+00:00
[2022-11-17T17:24:54.460+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.195 seconds
[2022-11-17T17:25:24.690+0000] {processor.py:154} INFO - Started process (PID=1260) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:25:24.693+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:25:24.694+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:25:24.694+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:25:24.718+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:25:24.745+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:25:24.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:25:24.761+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:25:24.761+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:25:24.772+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T17:25:55.093+0000] {processor.py:154} INFO - Started process (PID=1291) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:25:55.096+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:25:55.099+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:25:55.099+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:25:55.136+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:25:55.176+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:25:55.176+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:25:55.195+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:25:55.195+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:25:55.211+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.125 seconds
[2022-11-17T17:26:25.455+0000] {processor.py:154} INFO - Started process (PID=1319) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:26:25.457+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:26:25.458+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:26:25.458+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:26:25.481+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:26:25.507+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:26:25.506+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:26:25.522+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:26:25.521+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:26:25.533+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.081 seconds
[2022-11-17T17:26:55.825+0000] {processor.py:154} INFO - Started process (PID=1348) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:26:55.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:26:55.828+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:26:55.828+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:26:55.851+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:26:55.881+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:26:55.881+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:26:55.899+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:26:55.899+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:26:55.910+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:27:25.985+0000] {processor.py:154} INFO - Started process (PID=1368) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:27:25.988+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:27:25.989+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:27:25.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:27:26.012+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:27:26.039+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:27:26.039+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:27:26.054+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:27:26.054+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:27:26.065+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T17:27:56.347+0000] {processor.py:154} INFO - Started process (PID=1399) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:27:56.350+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:27:56.351+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:27:56.351+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:27:56.376+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:27:56.403+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:27:56.403+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:27:56.417+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:27:56.417+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:27:56.429+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T17:28:26.820+0000] {processor.py:154} INFO - Started process (PID=1430) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:28:26.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:28:26.825+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:26.825+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:28:26.850+0000] {processor.py:766} INFO - DAG(s) dict_keys(['python_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:28:26.878+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:26.878+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:28:26.893+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:26.893+0000] {dag.py:3340} INFO - Setting next_dagrun for python_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:28:26.905+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:28:46.068+0000] {processor.py:154} INFO - Started process (PID=1450) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:28:46.071+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:28:46.072+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:46.072+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:28:46.111+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:28:46.219+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:46.218+0000] {manager.py:507} INFO - Created Permission View: can read on DAG:spark_operator
[2022-11-17T17:28:46.225+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:46.225+0000] {manager.py:507} INFO - Created Permission View: can edit on DAG:spark_operator
[2022-11-17T17:28:46.231+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:46.231+0000] {manager.py:507} INFO - Created Permission View: can delete on DAG:spark_operator
[2022-11-17T17:28:46.232+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:46.232+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:28:46.240+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:46.240+0000] {dag.py:2606} INFO - Creating ORM DAG for spark_operator
[2022-11-17T17:28:46.250+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:28:46.250+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-16T00:00:00+00:00, run_after=2022-11-17T00:00:00+00:00
[2022-11-17T17:28:46.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.199 seconds
[2022-11-17T17:29:16.356+0000] {processor.py:154} INFO - Started process (PID=1484) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:29:16.359+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:29:16.360+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:29:16.360+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:29:16.378+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:29:16.407+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:29:16.406+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:29:16.436+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:29:16.436+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:29:16.464+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.110 seconds
[2022-11-17T17:29:46.746+0000] {processor.py:154} INFO - Started process (PID=1505) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:29:46.750+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:29:46.757+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:29:46.756+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:29:46.802+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:29:46.859+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:29:46.859+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:29:46.898+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:29:46.898+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:29:46.929+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.187 seconds
[2022-11-17T17:30:17.254+0000] {processor.py:154} INFO - Started process (PID=1535) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:30:17.257+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:30:17.259+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:30:17.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:30:17.284+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:30:17.312+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:30:17.312+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:30:17.328+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:30:17.328+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:30:17.339+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:30:47.681+0000] {processor.py:154} INFO - Started process (PID=1565) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:30:47.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:30:47.686+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:30:47.686+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:30:47.707+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:30:47.731+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:30:47.731+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:30:47.746+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:30:47.746+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:30:47.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.079 seconds
[2022-11-17T17:31:18.163+0000] {processor.py:154} INFO - Started process (PID=1595) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:31:18.173+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:31:18.175+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:31:18.175+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:31:18.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:31:18.233+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:31:18.233+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:31:18.248+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:31:18.247+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:31:18.259+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.099 seconds
[2022-11-17T17:31:48.592+0000] {processor.py:154} INFO - Started process (PID=1625) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:31:48.594+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:31:48.595+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:31:48.595+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:31:48.612+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:31:48.637+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:31:48.637+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:31:48.653+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:31:48.653+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:31:48.665+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.075 seconds
[2022-11-17T17:32:19.034+0000] {processor.py:154} INFO - Started process (PID=1647) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:32:19.036+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:32:19.038+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:32:19.038+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:32:19.059+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:32:19.085+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:32:19.085+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:32:19.102+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:32:19.102+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:32:19.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.083 seconds
[2022-11-17T17:32:49.500+0000] {processor.py:154} INFO - Started process (PID=1677) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:32:49.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:32:49.506+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:32:49.506+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:32:49.529+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:32:49.556+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:32:49.556+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:32:49.572+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:32:49.572+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:32:49.583+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T17:33:19.926+0000] {processor.py:154} INFO - Started process (PID=1707) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:33:19.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:33:19.933+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:33:19.933+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:33:19.961+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:33:19.986+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:33:19.986+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:33:20.001+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:33:20.001+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:33:20.011+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:33:50.355+0000] {processor.py:154} INFO - Started process (PID=1736) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:33:50.382+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:33:50.386+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:33:50.386+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:33:50.408+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:33:50.435+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:33:50.435+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:33:50.451+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:33:50.450+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:33:50.461+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.109 seconds
[2022-11-17T17:34:20.791+0000] {processor.py:154} INFO - Started process (PID=1767) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:34:20.793+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:34:20.795+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:34:20.794+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:34:20.821+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:34:20.862+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:34:20.862+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:34:20.891+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:34:20.890+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:34:20.915+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.128 seconds
[2022-11-17T17:34:51.211+0000] {processor.py:154} INFO - Started process (PID=1789) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:34:51.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:34:51.214+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:34:51.214+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:34:51.230+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:34:51.254+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:34:51.254+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:34:51.267+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:34:51.267+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:34:51.278+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.070 seconds
[2022-11-17T17:35:21.595+0000] {processor.py:154} INFO - Started process (PID=1818) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:35:21.597+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:35:21.599+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:35:21.599+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:35:21.620+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:35:21.644+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:35:21.644+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:35:21.659+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:35:21.659+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:35:21.670+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.078 seconds
[2022-11-17T17:35:51.975+0000] {processor.py:154} INFO - Started process (PID=1848) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:35:51.978+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:35:51.980+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:35:51.980+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:35:52.003+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:35:52.031+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:35:52.031+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:35:52.049+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:35:52.049+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:35:52.061+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.090 seconds
[2022-11-17T17:36:22.419+0000] {processor.py:154} INFO - Started process (PID=1879) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:36:22.421+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:36:22.423+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:36:22.422+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:36:22.447+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:36:22.473+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:36:22.473+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:36:22.489+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:36:22.488+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:36:22.499+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.083 seconds
[2022-11-17T17:36:52.841+0000] {processor.py:154} INFO - Started process (PID=1909) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:36:52.843+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:36:52.844+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:36:52.844+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:36:52.863+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:36:52.888+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:36:52.888+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:36:52.903+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:36:52.902+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:36:52.914+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.075 seconds
[2022-11-17T17:37:23.239+0000] {processor.py:154} INFO - Started process (PID=1930) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:37:23.241+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:37:23.243+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:37:23.242+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:37:23.258+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:37:23.287+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:37:23.287+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:37:23.306+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:37:23.306+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:37:23.329+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.093 seconds
[2022-11-17T17:37:53.745+0000] {processor.py:154} INFO - Started process (PID=1960) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:37:53.748+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:37:53.749+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:37:53.749+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:37:53.775+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:37:53.803+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:37:53.803+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:37:53.817+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:37:53.817+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:37:53.828+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T17:38:24.110+0000] {processor.py:154} INFO - Started process (PID=1990) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:38:24.112+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:38:24.114+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:38:24.114+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:38:24.139+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:38:24.163+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:38:24.163+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:38:24.177+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:38:24.177+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:38:24.187+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.081 seconds
[2022-11-17T17:38:54.368+0000] {processor.py:154} INFO - Started process (PID=2020) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:38:54.371+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:38:54.374+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:38:54.373+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:38:54.403+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:38:54.431+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:38:54.431+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:38:54.449+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:38:54.449+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:38:54.460+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.097 seconds
[2022-11-17T17:39:24.771+0000] {processor.py:154} INFO - Started process (PID=2050) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:39:24.773+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:39:24.775+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:39:24.775+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:39:24.797+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:39:24.827+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:39:24.826+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:39:24.851+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:39:24.851+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:39:24.863+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.095 seconds
[2022-11-17T17:39:55.157+0000] {processor.py:154} INFO - Started process (PID=2070) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:39:55.160+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:39:55.161+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:39:55.161+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:39:55.179+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:39:55.206+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:39:55.205+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:39:55.222+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:39:55.222+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:39:55.233+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.079 seconds
[2022-11-17T17:40:25.527+0000] {processor.py:154} INFO - Started process (PID=2100) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:40:25.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:40:25.532+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:40:25.532+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:40:25.557+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:40:25.589+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:40:25.589+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:40:25.607+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:40:25.607+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:40:25.620+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.096 seconds
[2022-11-17T17:40:55.980+0000] {processor.py:154} INFO - Started process (PID=2130) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:40:55.983+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:40:55.985+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:40:55.984+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:40:56.011+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:40:56.038+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:40:56.038+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:40:56.053+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:40:56.053+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:40:56.063+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T17:41:26.350+0000] {processor.py:154} INFO - Started process (PID=2162) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:41:26.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:41:26.355+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:41:26.355+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:41:26.379+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:41:26.404+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:41:26.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:41:26.418+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:41:26.418+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:41:26.428+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.081 seconds
[2022-11-17T17:41:56.716+0000] {processor.py:154} INFO - Started process (PID=2193) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:41:56.718+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:41:56.720+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:41:56.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:41:56.745+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:41:56.790+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:41:56.790+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:41:56.825+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:41:56.825+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:41:56.841+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.129 seconds
[2022-11-17T17:42:27.135+0000] {processor.py:154} INFO - Started process (PID=2215) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:42:27.138+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:42:27.139+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:42:27.139+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:42:27.163+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:42:27.189+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:42:27.189+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:42:27.204+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:42:27.204+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:42:27.214+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.083 seconds
[2022-11-17T17:42:57.520+0000] {processor.py:154} INFO - Started process (PID=2244) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:42:57.522+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:42:57.526+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:42:57.526+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:42:57.551+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:42:57.580+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:42:57.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:42:57.595+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:42:57.595+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:42:57.605+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:43:27.909+0000] {processor.py:154} INFO - Started process (PID=2273) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:43:27.912+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:43:27.914+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:43:27.914+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:43:27.940+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:43:27.969+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:43:27.969+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:43:27.983+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:43:27.983+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:43:27.994+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.088 seconds
[2022-11-17T17:43:58.333+0000] {processor.py:154} INFO - Started process (PID=2303) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:43:58.336+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:43:58.337+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:43:58.337+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:43:58.361+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:43:58.388+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:43:58.387+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:43:58.401+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:43:58.401+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:43:58.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T17:44:28.647+0000] {processor.py:154} INFO - Started process (PID=2332) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:44:28.650+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:44:28.653+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:44:28.652+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:44:28.688+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:44:28.727+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:44:28.727+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:44:28.742+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:44:28.742+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:44:28.754+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.113 seconds
[2022-11-17T17:44:59.092+0000] {processor.py:154} INFO - Started process (PID=2353) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:44:59.095+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:44:59.098+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:44:59.098+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:44:59.123+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:44:59.152+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:44:59.151+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:44:59.167+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:44:59.167+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:44:59.178+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:45:29.555+0000] {processor.py:154} INFO - Started process (PID=2383) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:45:29.557+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:45:29.559+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:45:29.559+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:45:29.582+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:45:29.610+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:45:29.610+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:45:29.625+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:45:29.625+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:45:29.636+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T17:45:59.970+0000] {processor.py:154} INFO - Started process (PID=2412) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:45:59.973+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:45:59.974+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:45:59.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:46:00.001+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:46:00.037+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:46:00.036+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:46:00.061+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:46:00.061+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:46:00.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.117 seconds
[2022-11-17T17:46:30.391+0000] {processor.py:154} INFO - Started process (PID=2443) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:46:30.394+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:46:30.395+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:46:30.395+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:46:30.420+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:46:30.448+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:46:30.448+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:46:30.462+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:46:30.462+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:46:30.472+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T17:47:00.912+0000] {processor.py:154} INFO - Started process (PID=2473) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:47:00.914+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:47:00.915+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:47:00.915+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:47:00.933+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:47:00.959+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:47:00.959+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:47:00.976+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:47:00.976+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:47:00.989+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.079 seconds
[2022-11-17T17:47:31.359+0000] {processor.py:154} INFO - Started process (PID=2494) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:47:31.362+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:47:31.363+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:47:31.363+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:47:31.387+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:47:31.414+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:47:31.414+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:47:31.429+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:47:31.428+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:47:31.440+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T17:48:01.835+0000] {processor.py:154} INFO - Started process (PID=2524) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:48:01.838+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:48:01.839+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:48:01.839+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:48:01.865+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:48:01.893+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:48:01.893+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:48:01.907+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:48:01.907+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:48:01.917+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.088 seconds
[2022-11-17T17:48:32.283+0000] {processor.py:154} INFO - Started process (PID=2554) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:48:32.287+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:48:32.288+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:48:32.288+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:48:32.313+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:48:32.340+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:48:32.339+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:48:32.356+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:48:32.356+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:48:32.369+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.090 seconds
[2022-11-17T17:49:02.683+0000] {processor.py:154} INFO - Started process (PID=2583) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:49:02.686+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:49:02.687+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:49:02.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:49:02.714+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:49:02.743+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:49:02.742+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:49:02.760+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:49:02.760+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:49:02.771+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.092 seconds
[2022-11-17T17:49:33.128+0000] {processor.py:154} INFO - Started process (PID=2614) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:49:33.130+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:49:33.132+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:49:33.131+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:49:33.148+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:49:33.174+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:49:33.174+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:49:33.190+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:49:33.190+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:49:33.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.076 seconds
[2022-11-17T17:50:03.532+0000] {processor.py:154} INFO - Started process (PID=2636) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:50:03.535+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:50:03.537+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:50:03.537+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:50:03.564+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:50:03.597+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:50:03.597+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:50:03.612+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:50:03.612+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:50:03.623+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.095 seconds
[2022-11-17T17:50:33.900+0000] {processor.py:154} INFO - Started process (PID=2666) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:50:33.904+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:50:33.906+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:50:33.906+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:50:33.938+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:50:33.967+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:50:33.967+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:50:33.983+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:50:33.983+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:50:33.995+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.101 seconds
[2022-11-17T17:51:04.298+0000] {processor.py:154} INFO - Started process (PID=2696) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:51:04.301+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:51:04.302+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:51:04.302+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:51:04.323+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:51:04.347+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:51:04.347+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:51:04.362+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:51:04.361+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:51:04.372+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.077 seconds
[2022-11-17T17:51:34.751+0000] {processor.py:154} INFO - Started process (PID=2726) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:51:34.754+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:51:34.755+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:51:34.755+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:51:34.781+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:51:34.810+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:51:34.809+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:51:34.826+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:51:34.826+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:51:34.836+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:52:05.178+0000] {processor.py:154} INFO - Started process (PID=2756) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:52:05.181+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:52:05.184+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:52:05.184+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:52:05.227+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:52:05.270+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:52:05.269+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:52:05.288+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:52:05.288+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:52:05.303+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.134 seconds
[2022-11-17T17:52:35.676+0000] {processor.py:154} INFO - Started process (PID=2776) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:52:35.678+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:52:35.679+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:52:35.679+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:52:35.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:52:35.729+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:52:35.729+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:52:35.743+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:52:35.743+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:52:35.753+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.081 seconds
[2022-11-17T17:53:06.071+0000] {processor.py:154} INFO - Started process (PID=2808) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:53:06.073+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:53:06.075+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:53:06.075+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:53:06.100+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:53:06.127+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:53:06.127+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:53:06.141+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:53:06.141+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:53:06.151+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T17:53:36.466+0000] {processor.py:154} INFO - Started process (PID=2838) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:53:36.468+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:53:36.470+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:53:36.470+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:53:36.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:53:36.523+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:53:36.523+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:53:36.537+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:53:36.537+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:53:36.548+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T17:54:06.850+0000] {processor.py:154} INFO - Started process (PID=2868) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:54:06.853+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:54:06.854+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:54:06.854+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:54:06.883+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:54:06.910+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:54:06.910+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:54:06.925+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:54:06.924+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:54:06.934+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:54:37.222+0000] {processor.py:154} INFO - Started process (PID=2899) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:54:37.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:54:37.225+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:54:37.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:54:37.240+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:54:37.266+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:54:37.266+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:54:37.284+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:54:37.283+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:54:37.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.076 seconds
[2022-11-17T17:55:07.620+0000] {processor.py:154} INFO - Started process (PID=2920) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:55:07.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:55:07.625+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:55:07.625+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:55:07.653+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:55:07.681+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:55:07.680+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:55:07.696+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:55:07.696+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:55:07.706+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.090 seconds
[2022-11-17T17:55:38.062+0000] {processor.py:154} INFO - Started process (PID=2951) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:55:38.065+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:55:38.067+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:55:38.066+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:55:38.088+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:55:38.115+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:55:38.115+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:55:38.129+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:55:38.129+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:55:38.139+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.080 seconds
[2022-11-17T17:56:08.479+0000] {processor.py:154} INFO - Started process (PID=2982) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:56:08.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:56:08.483+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:56:08.483+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:56:08.508+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:56:08.536+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:56:08.536+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:56:08.551+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:56:08.551+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:56:08.562+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T17:56:38.840+0000] {processor.py:154} INFO - Started process (PID=3011) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:56:38.843+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:56:38.846+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:56:38.846+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:56:38.870+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:56:38.897+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:56:38.897+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:56:38.911+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:56:38.911+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:56:38.961+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.124 seconds
[2022-11-17T17:57:09.294+0000] {processor.py:154} INFO - Started process (PID=3042) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:57:09.296+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:57:09.297+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:57:09.297+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:57:09.313+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:57:09.337+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:57:09.337+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:57:09.351+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:57:09.351+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:57:09.361+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.070 seconds
[2022-11-17T17:57:39.723+0000] {processor.py:154} INFO - Started process (PID=3063) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:57:39.726+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:57:39.728+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:57:39.728+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:57:39.751+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:57:39.780+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:57:39.780+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:57:39.794+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:57:39.793+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:57:39.805+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T17:58:10.147+0000] {processor.py:154} INFO - Started process (PID=3094) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:58:10.149+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:58:10.151+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:58:10.151+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:58:10.178+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:58:10.206+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:58:10.206+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:58:10.221+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:58:10.221+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:58:10.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T17:58:40.610+0000] {processor.py:154} INFO - Started process (PID=3124) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:58:40.612+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:58:40.614+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:58:40.613+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:58:40.631+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:58:40.658+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:58:40.658+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:58:40.673+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:58:40.673+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:58:40.686+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.079 seconds
[2022-11-17T17:59:10.994+0000] {processor.py:154} INFO - Started process (PID=3153) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:59:10.996+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:59:10.998+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:59:10.998+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:59:11.023+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:59:11.048+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:59:11.048+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:59:11.063+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:59:11.063+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:59:11.074+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.083 seconds
[2022-11-17T17:59:41.480+0000] {processor.py:154} INFO - Started process (PID=3182) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:59:41.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T17:59:41.484+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:59:41.484+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:59:41.503+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T17:59:41.531+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:59:41.531+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T17:59:41.548+0000] {logging_mixin.py:137} INFO - [2022-11-17T17:59:41.548+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T17:59:41.560+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.083 seconds
[2022-11-17T18:00:11.871+0000] {processor.py:154} INFO - Started process (PID=3203) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:00:11.874+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:00:11.876+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:00:11.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:00:11.901+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:00:11.932+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:00:11.932+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:00:11.950+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:00:11.950+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:00:11.966+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.097 seconds
[2022-11-17T18:00:42.389+0000] {processor.py:154} INFO - Started process (PID=3233) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:00:42.392+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:00:42.393+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:00:42.393+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:00:42.417+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:00:42.443+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:00:42.443+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:00:42.458+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:00:42.458+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:00:42.469+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T18:01:12.865+0000] {processor.py:154} INFO - Started process (PID=3263) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:01:12.869+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:01:12.870+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:01:12.870+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:01:12.905+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:01:12.955+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:01:12.955+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:01:12.993+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:01:12.993+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:01:13.027+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.165 seconds
[2022-11-17T18:01:35.349+0000] {processor.py:154} INFO - Started process (PID=3282) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:01:35.352+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:01:35.354+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:01:35.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:01:35.393+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:01:35.426+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:01:35.425+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:01:35.446+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:01:35.446+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:01:35.465+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.122 seconds
[2022-11-17T18:02:05.692+0000] {processor.py:154} INFO - Started process (PID=3312) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:02:05.694+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:02:05.696+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:02:05.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:02:05.728+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:02:05.761+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:02:05.761+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:02:05.781+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:02:05.781+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:02:05.792+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.105 seconds
[2022-11-17T18:02:36.073+0000] {processor.py:154} INFO - Started process (PID=3342) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:02:36.075+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:02:36.076+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:02:36.076+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:02:36.097+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:02:36.136+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:02:36.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:02:36.152+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:02:36.152+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:02:36.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.092 seconds
[2022-11-17T18:03:06.462+0000] {processor.py:154} INFO - Started process (PID=3363) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:03:06.465+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:03:06.467+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:03:06.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:03:06.494+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:03:06.528+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:03:06.527+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:03:06.547+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:03:06.547+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:03:06.561+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.102 seconds
[2022-11-17T18:03:36.865+0000] {processor.py:154} INFO - Started process (PID=3392) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:03:36.868+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:03:36.870+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:03:36.870+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:03:36.902+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:03:36.934+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:03:36.934+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:03:36.951+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:03:36.951+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:03:36.963+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.104 seconds
[2022-11-17T18:04:07.256+0000] {processor.py:154} INFO - Started process (PID=3422) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:04:07.259+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:04:07.261+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:04:07.261+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:04:07.286+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:04:07.315+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:04:07.315+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:04:07.334+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:04:07.334+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:04:07.347+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.095 seconds
[2022-11-17T18:04:37.802+0000] {processor.py:154} INFO - Started process (PID=3452) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:04:37.805+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:04:37.807+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:04:37.807+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:04:37.838+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:04:37.870+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:04:37.870+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:04:37.888+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:04:37.888+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:04:37.900+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.104 seconds
[2022-11-17T18:05:08.225+0000] {processor.py:154} INFO - Started process (PID=3482) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:05:08.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:05:08.231+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:05:08.231+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:05:08.272+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:05:08.308+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:05:08.308+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:05:08.327+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:05:08.327+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:05:08.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.122 seconds
[2022-11-17T18:05:38.625+0000] {processor.py:154} INFO - Started process (PID=3510) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:05:38.627+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:05:38.628+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:05:38.628+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:05:38.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:05:38.667+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:05:38.667+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:05:38.682+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:05:38.681+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:05:38.694+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.071 seconds
[2022-11-17T18:06:08.997+0000] {processor.py:154} INFO - Started process (PID=3531) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:06:08.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:06:09.001+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:06:09.001+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:06:09.034+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:06:09.065+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:06:09.065+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:06:09.083+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:06:09.083+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:06:09.094+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.102 seconds
[2022-11-17T18:06:39.365+0000] {processor.py:154} INFO - Started process (PID=3563) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:06:39.368+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:06:39.369+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:06:39.369+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:06:39.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:06:39.444+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:06:39.443+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:06:39.465+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:06:39.464+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:06:39.480+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.121 seconds
[2022-11-17T18:07:09.742+0000] {processor.py:154} INFO - Started process (PID=3591) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:07:09.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:07:09.746+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:07:09.746+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:07:09.782+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:07:09.820+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:07:09.820+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:07:09.837+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:07:09.837+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:07:09.852+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.115 seconds
[2022-11-17T18:07:40.216+0000] {processor.py:154} INFO - Started process (PID=3621) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:07:40.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:07:40.220+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:07:40.220+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:07:40.244+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:07:40.271+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:07:40.271+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:07:40.286+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:07:40.286+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:07:40.297+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T18:08:10.652+0000] {processor.py:154} INFO - Started process (PID=3649) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:08:10.654+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:08:10.656+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:08:10.656+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:08:10.719+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:08:10.813+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:08:10.813+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:08:10.865+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:08:10.865+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:08:10.914+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.266 seconds
[2022-11-17T18:08:41.134+0000] {processor.py:154} INFO - Started process (PID=3670) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:08:41.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:08:41.138+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:08:41.138+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:08:41.164+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:08:41.193+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:08:41.193+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:08:41.208+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:08:41.208+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:08:41.220+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.090 seconds
[2022-11-17T18:09:11.490+0000] {processor.py:154} INFO - Started process (PID=3700) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:09:11.493+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:09:11.494+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:09:11.494+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:09:11.521+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:09:11.550+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:09:11.550+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:09:11.566+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:09:11.566+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:09:11.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.092 seconds
[2022-11-17T18:09:42.011+0000] {processor.py:154} INFO - Started process (PID=3730) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:09:42.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:09:42.016+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:09:42.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:09:42.039+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:09:42.067+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:09:42.067+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:09:42.082+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:09:42.082+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:09:42.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T18:10:12.410+0000] {processor.py:154} INFO - Started process (PID=3758) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:10:12.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:10:12.417+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:10:12.417+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:10:12.449+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:10:12.488+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:10:12.488+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:10:12.505+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:10:12.505+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:10:12.518+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.114 seconds
[2022-11-17T18:10:42.761+0000] {processor.py:154} INFO - Started process (PID=3788) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:10:42.764+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:10:42.765+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:10:42.765+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:10:42.784+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:10:42.813+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:10:42.813+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:10:42.831+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:10:42.831+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:10:42.844+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T18:11:13.150+0000] {processor.py:154} INFO - Started process (PID=3809) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:11:13.156+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:11:13.158+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:11:13.158+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:11:13.206+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:11:13.262+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:11:13.262+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:11:13.293+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:11:13.293+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:11:13.304+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.160 seconds
[2022-11-17T18:11:43.654+0000] {processor.py:154} INFO - Started process (PID=3839) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:11:43.657+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:11:43.659+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:11:43.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:11:43.690+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:11:43.716+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:11:43.716+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:11:43.732+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:11:43.731+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:11:43.743+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.094 seconds
[2022-11-17T18:12:14.131+0000] {processor.py:154} INFO - Started process (PID=3870) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:12:14.136+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:12:14.139+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:12:14.138+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:12:14.168+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:12:14.217+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:12:14.216+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:12:14.233+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:12:14.233+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:12:14.246+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.121 seconds
[2022-11-17T18:12:44.610+0000] {processor.py:154} INFO - Started process (PID=3902) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:12:44.612+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:12:44.614+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:12:44.613+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:12:44.636+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:12:44.677+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:12:44.677+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:12:44.693+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:12:44.693+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:12:44.705+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.100 seconds
[2022-11-17T18:13:15.088+0000] {processor.py:154} INFO - Started process (PID=3921) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:13:15.092+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:13:15.094+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:13:15.093+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:13:15.129+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:13:15.230+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:13:15.230+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:13:15.257+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:13:15.256+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:13:15.270+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.187 seconds
[2022-11-17T18:13:45.550+0000] {processor.py:154} INFO - Started process (PID=3951) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:13:45.553+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:13:45.554+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:13:45.554+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:13:45.596+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:13:45.630+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:13:45.630+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:13:45.648+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:13:45.648+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:13:45.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.116 seconds
[2022-11-17T18:14:16.028+0000] {processor.py:154} INFO - Started process (PID=3981) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:14:16.032+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:14:16.034+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:14:16.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:14:16.071+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:14:16.109+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:14:16.108+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:14:16.127+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:14:16.127+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:14:16.142+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.120 seconds
[2022-11-17T18:14:46.373+0000] {processor.py:154} INFO - Started process (PID=4012) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:14:46.375+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:14:46.377+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:14:46.377+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:14:46.404+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:14:46.442+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:14:46.442+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:14:46.459+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:14:46.459+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:14:46.471+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.103 seconds
[2022-11-17T18:15:16.784+0000] {processor.py:154} INFO - Started process (PID=4042) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:15:16.786+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:15:16.787+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:15:16.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:15:16.817+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:15:16.856+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:15:16.856+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:15:16.886+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:15:16.886+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:15:16.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.123 seconds
[2022-11-17T18:15:47.253+0000] {processor.py:154} INFO - Started process (PID=4063) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:15:47.257+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:15:47.259+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:15:47.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:15:47.305+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:15:47.352+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:15:47.352+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:15:47.371+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:15:47.371+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:15:47.383+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.137 seconds
[2022-11-17T18:16:17.779+0000] {processor.py:154} INFO - Started process (PID=4093) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:16:17.783+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:16:17.785+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:16:17.785+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:16:17.824+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:16:17.864+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:16:17.864+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:16:17.882+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:16:17.882+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:16:17.895+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.122 seconds
[2022-11-17T18:16:48.230+0000] {processor.py:154} INFO - Started process (PID=4124) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:16:48.233+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:16:48.234+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:16:48.234+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:16:48.264+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:16:48.308+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:16:48.308+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:16:48.328+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:16:48.328+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:16:48.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.114 seconds
[2022-11-17T18:17:18.671+0000] {processor.py:154} INFO - Started process (PID=4154) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:17:18.674+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:17:18.676+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:17:18.675+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:17:18.715+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:17:18.753+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:17:18.753+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:17:18.776+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:17:18.776+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:17:18.789+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.121 seconds
[2022-11-17T18:17:49.132+0000] {processor.py:154} INFO - Started process (PID=4185) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:17:49.134+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:17:49.135+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:17:49.135+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:17:49.166+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:17:49.204+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:17:49.204+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:17:49.229+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:17:49.229+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:17:49.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.133 seconds
[2022-11-17T18:18:19.623+0000] {processor.py:154} INFO - Started process (PID=4206) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:18:19.627+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:18:19.628+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:18:19.628+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:18:19.675+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:18:19.709+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:18:19.709+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:18:19.732+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:18:19.732+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:18:19.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.126 seconds
[2022-11-17T18:18:49.956+0000] {processor.py:154} INFO - Started process (PID=4236) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:18:49.963+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:18:49.965+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:18:49.965+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:18:50.000+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:18:50.034+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:18:50.034+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:18:50.057+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:18:50.057+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:18:50.073+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.123 seconds
[2022-11-17T18:19:20.356+0000] {processor.py:154} INFO - Started process (PID=4266) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:19:20.359+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:19:20.362+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:19:20.361+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:19:20.451+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:19:20.492+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:19:20.492+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:19:20.513+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:19:20.513+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:19:20.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.177 seconds
[2022-11-17T18:19:50.726+0000] {processor.py:154} INFO - Started process (PID=4296) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:19:50.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:19:50.734+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:19:50.734+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:19:50.760+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:19:50.792+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:19:50.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:19:50.811+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:19:50.811+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:19:50.827+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.108 seconds
[2022-11-17T18:20:21.143+0000] {processor.py:154} INFO - Started process (PID=4316) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:20:21.146+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:20:21.147+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:20:21.147+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:20:21.197+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:20:21.231+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:20:21.231+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:20:21.249+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:20:21.249+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:20:21.262+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.124 seconds
[2022-11-17T18:20:51.527+0000] {processor.py:154} INFO - Started process (PID=4346) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:20:51.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:20:51.532+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:20:51.532+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:20:51.565+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:20:51.610+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:20:51.610+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:20:51.629+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:20:51.629+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:20:51.640+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.117 seconds
[2022-11-17T18:21:21.936+0000] {processor.py:154} INFO - Started process (PID=4375) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:21:21.938+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:21:21.939+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:21:21.939+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:21:21.964+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:21:22.025+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:21:22.023+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:21:22.054+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:21:22.054+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:21:22.069+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.137 seconds
[2022-11-17T18:21:52.385+0000] {processor.py:154} INFO - Started process (PID=4404) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:21:52.390+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:21:52.393+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:21:52.392+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:21:52.434+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:21:52.472+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:21:52.472+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:21:52.493+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:21:52.493+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:21:52.504+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.127 seconds
[2022-11-17T18:22:22.847+0000] {processor.py:154} INFO - Started process (PID=4432) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:22:22.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:22:22.851+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:22:22.850+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:22:22.873+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:22:22.905+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:22:22.904+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:22:22.920+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:22:22.920+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:22:22.931+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.088 seconds
[2022-11-17T18:22:53.322+0000] {processor.py:154} INFO - Started process (PID=4453) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:22:53.325+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:22:53.327+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:22:53.327+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:22:53.362+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:22:53.404+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:22:53.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:22:53.426+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:22:53.426+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:22:53.438+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.122 seconds
[2022-11-17T18:23:23.718+0000] {processor.py:154} INFO - Started process (PID=4482) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:23:23.723+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:23:23.725+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:23:23.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:23:23.759+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:23:23.792+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:23:23.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:23:23.812+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:23:23.812+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:23:23.824+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.112 seconds
[2022-11-17T18:23:54.126+0000] {processor.py:154} INFO - Started process (PID=4512) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:23:54.129+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:23:54.130+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:23:54.130+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:23:54.154+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:23:54.181+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:23:54.181+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:23:54.196+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:23:54.196+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:23:54.206+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T18:24:24.512+0000] {processor.py:154} INFO - Started process (PID=4542) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:24:24.514+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:24:24.516+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:24:24.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:24:24.551+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:24:24.621+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:24:24.621+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:24:24.655+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:24:24.655+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:24:24.681+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.173 seconds
[2022-11-17T18:24:54.929+0000] {processor.py:154} INFO - Started process (PID=4573) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:24:54.932+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:24:54.934+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:24:54.934+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:24:54.961+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:24:54.991+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:24:54.991+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:24:55.008+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:24:55.008+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:24:55.022+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.095 seconds
[2022-11-17T18:25:25.306+0000] {processor.py:154} INFO - Started process (PID=4594) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:25:25.308+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:25:25.309+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:25:25.309+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:25:25.325+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:25:25.353+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:25:25.353+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:25:25.369+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:25:25.369+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:25:25.381+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.078 seconds
[2022-11-17T18:25:55.697+0000] {processor.py:154} INFO - Started process (PID=4626) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:25:55.701+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:25:55.703+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:25:55.703+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:25:55.739+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:25:55.775+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:25:55.775+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:25:55.795+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:25:55.795+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:25:55.809+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.116 seconds
[2022-11-17T18:26:26.102+0000] {processor.py:154} INFO - Started process (PID=4656) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:26:26.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:26:26.107+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:26:26.107+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:26:26.132+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:26:26.159+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:26:26.159+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:26:26.175+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:26:26.175+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:26:26.186+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T18:26:56.583+0000] {processor.py:154} INFO - Started process (PID=4686) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:26:56.586+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:26:56.587+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:26:56.587+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:26:56.611+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:26:56.643+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:26:56.643+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:26:56.661+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:26:56.661+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:26:56.673+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.093 seconds
[2022-11-17T18:27:27.095+0000] {processor.py:154} INFO - Started process (PID=4717) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:27:27.097+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:27:27.098+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:27:27.098+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:27:27.114+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:27:27.140+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:27:27.139+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:27:27.155+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:27:27.154+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:27:27.166+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.073 seconds
[2022-11-17T18:27:57.577+0000] {processor.py:154} INFO - Started process (PID=4738) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:27:57.580+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:27:57.582+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:27:57.582+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:27:57.609+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:27:57.640+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:27:57.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:27:57.654+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:27:57.654+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:27:57.665+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.091 seconds
[2022-11-17T18:28:28.086+0000] {processor.py:154} INFO - Started process (PID=4768) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:28:28.090+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:28:28.093+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:28:28.092+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:28:28.125+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:28:28.162+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:28:28.162+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:28:28.179+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:28:28.179+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:28:28.191+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.110 seconds
[2022-11-17T18:28:58.441+0000] {processor.py:154} INFO - Started process (PID=4798) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:28:58.444+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:28:58.445+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:28:58.445+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:28:58.477+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:28:58.502+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:28:58.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:28:58.517+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:28:58.516+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:28:58.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.090 seconds
[2022-11-17T18:29:28.963+0000] {processor.py:154} INFO - Started process (PID=4829) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:29:28.966+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:29:28.967+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:29:28.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:29:28.993+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:29:29.023+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:29:29.023+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:29:29.043+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:29:29.043+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:29:29.059+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.100 seconds
[2022-11-17T18:29:59.343+0000] {processor.py:154} INFO - Started process (PID=4859) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:29:59.347+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:29:59.385+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:29:59.385+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:29:59.467+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:29:59.523+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:29:59.523+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:29:59.553+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:29:59.553+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:29:59.597+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.257 seconds
[2022-11-17T18:30:29.784+0000] {processor.py:154} INFO - Started process (PID=4880) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:30:29.787+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:30:29.789+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:30:29.789+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:30:29.814+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:30:29.841+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:30:29.841+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:30:29.857+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:30:29.857+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:30:29.868+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.087 seconds
[2022-11-17T18:31:00.266+0000] {processor.py:154} INFO - Started process (PID=4910) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:31:00.269+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:31:00.271+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:31:00.271+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:31:00.309+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:31:00.347+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:31:00.347+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:31:00.366+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:31:00.366+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:31:00.387+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.127 seconds
[2022-11-17T18:31:30.680+0000] {processor.py:154} INFO - Started process (PID=4940) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:31:30.683+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:31:30.686+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:31:30.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:31:30.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:31:30.748+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:31:30.748+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:31:30.767+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:31:30.767+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:31:30.779+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.104 seconds
[2022-11-17T18:32:01.061+0000] {processor.py:154} INFO - Started process (PID=4970) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:32:01.065+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:32:01.066+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:32:01.066+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:32:01.107+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:32:01.151+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:32:01.151+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:32:01.169+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:32:01.169+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:32:01.183+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.128 seconds
[2022-11-17T18:32:31.426+0000] {processor.py:154} INFO - Started process (PID=5000) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:32:31.428+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:32:31.430+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:32:31.430+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:32:31.464+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:32:31.498+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:32:31.498+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:32:31.517+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:32:31.517+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:32:31.528+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.105 seconds
[2022-11-17T18:33:01.928+0000] {processor.py:154} INFO - Started process (PID=5021) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:33:01.930+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:33:01.931+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:33:01.931+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:33:01.956+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:33:01.984+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:33:01.984+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:33:01.999+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:33:01.999+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:33:02.011+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.087 seconds
[2022-11-17T18:33:32.349+0000] {processor.py:154} INFO - Started process (PID=5050) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:33:32.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:33:32.356+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:33:32.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:33:32.388+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:33:32.415+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:33:32.415+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:33:32.431+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:33:32.431+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:33:32.443+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.098 seconds
[2022-11-17T18:34:02.761+0000] {processor.py:154} INFO - Started process (PID=5079) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:34:02.763+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:34:02.765+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:34:02.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:34:02.795+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:34:02.840+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:34:02.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:34:02.859+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:34:02.859+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:34:02.870+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.112 seconds
[2022-11-17T18:34:33.312+0000] {processor.py:154} INFO - Started process (PID=5109) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:34:33.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:34:33.316+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:34:33.316+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:34:33.347+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:34:33.379+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:34:33.379+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:34:33.396+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:34:33.396+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:34:33.408+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.102 seconds
[2022-11-17T18:35:03.650+0000] {processor.py:154} INFO - Started process (PID=5139) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:35:03.653+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:35:03.655+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:35:03.655+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:35:03.682+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:35:03.716+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:35:03.716+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:35:03.738+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:35:03.738+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:35:03.751+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.105 seconds
[2022-11-17T18:35:34.056+0000] {processor.py:154} INFO - Started process (PID=5169) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:35:34.060+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:35:34.061+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:35:34.061+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:35:34.097+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:35:34.130+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:35:34.130+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:35:34.151+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:35:34.151+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:35:34.167+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.115 seconds
[2022-11-17T18:36:04.543+0000] {processor.py:154} INFO - Started process (PID=5191) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:36:04.546+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:36:04.547+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:36:04.547+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:36:04.590+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:36:04.631+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:36:04.630+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:36:04.661+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:36:04.661+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:36:04.674+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.136 seconds
[2022-11-17T18:36:34.944+0000] {processor.py:154} INFO - Started process (PID=5222) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:36:34.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:36:34.949+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:36:34.949+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:36:34.976+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:36:35.007+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:36:35.007+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:36:35.025+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:36:35.025+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:36:35.037+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.099 seconds
[2022-11-17T18:37:05.328+0000] {processor.py:154} INFO - Started process (PID=5251) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:37:05.332+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:37:05.334+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:37:05.334+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:37:05.370+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:37:05.411+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:37:05.411+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:37:05.434+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:37:05.434+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:37:05.446+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.124 seconds
[2022-11-17T18:37:35.823+0000] {processor.py:154} INFO - Started process (PID=5281) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:37:35.830+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:37:35.836+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:37:35.836+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:37:35.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:37:35.912+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:37:35.912+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:37:35.930+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:37:35.930+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:37:35.945+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.128 seconds
[2022-11-17T18:38:06.329+0000] {processor.py:154} INFO - Started process (PID=5301) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:38:06.333+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:38:06.335+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:38:06.335+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:38:06.364+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:38:06.392+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:38:06.392+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:38:06.409+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:38:06.409+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:38:06.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.097 seconds
[2022-11-17T18:38:36.729+0000] {processor.py:154} INFO - Started process (PID=5332) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:38:36.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:38:36.733+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:38:36.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:38:36.766+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:38:36.798+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:38:36.798+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:38:36.815+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:38:36.814+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:38:36.826+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.104 seconds
[2022-11-17T18:39:07.179+0000] {processor.py:154} INFO - Started process (PID=5361) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:39:07.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:39:07.185+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:39:07.185+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:39:07.209+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:39:07.237+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:39:07.237+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:39:07.253+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:39:07.253+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:39:07.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.089 seconds
[2022-11-17T18:39:37.724+0000] {processor.py:154} INFO - Started process (PID=5392) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:39:37.727+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:39:37.729+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:39:37.729+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:39:37.760+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:39:37.791+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:39:37.791+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:39:37.808+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:39:37.808+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:39:37.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.103 seconds
[2022-11-17T18:40:08.171+0000] {processor.py:154} INFO - Started process (PID=5422) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:40:08.174+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:40:08.177+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:40:08.176+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:40:08.199+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:40:08.225+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:40:08.225+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:40:08.240+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:40:08.240+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:40:08.250+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.083 seconds
[2022-11-17T18:40:38.585+0000] {processor.py:154} INFO - Started process (PID=5444) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:40:38.587+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T18:40:38.589+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:40:38.589+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:40:38.619+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T18:40:38.663+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:40:38.663+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T18:40:38.686+0000] {logging_mixin.py:137} INFO - [2022-11-17T18:40:38.685+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T18:40:38.699+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.118 seconds
[2022-11-17T19:18:09.085+0000] {processor.py:154} INFO - Started process (PID=33) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:18:09.090+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:18:09.092+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:18:09.092+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:18:09.170+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:18:09.210+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:18:09.206+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:18:09.249+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:18:09.249+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:18:09.271+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.192 seconds
[2022-11-17T19:18:39.552+0000] {processor.py:154} INFO - Started process (PID=63) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:18:39.555+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:18:39.557+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:18:39.557+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:18:39.587+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:18:39.615+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:18:39.615+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:18:39.629+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:18:39.629+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:18:39.641+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.094 seconds
[2022-11-17T19:19:09.897+0000] {processor.py:154} INFO - Started process (PID=93) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:19:09.911+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:19:09.914+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:19:09.914+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:19:09.937+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:19:09.961+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:19:09.961+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:19:09.975+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:19:09.975+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:19:09.985+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.093 seconds
[2022-11-17T19:19:40.229+0000] {processor.py:154} INFO - Started process (PID=123) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:19:40.231+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:19:40.232+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:19:40.232+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:19:40.247+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:19:40.269+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:19:40.269+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:19:40.284+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:19:40.284+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:19:40.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.068 seconds
[2022-11-17T19:20:10.553+0000] {processor.py:154} INFO - Started process (PID=144) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:20:10.560+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:20:10.566+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:20:10.566+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:20:10.591+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:20:10.616+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:20:10.616+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:20:10.631+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:20:10.631+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:20:10.643+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.096 seconds
[2022-11-17T19:20:41.020+0000] {processor.py:154} INFO - Started process (PID=174) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:20:41.023+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:20:41.025+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:20:41.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:20:41.049+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:20:41.074+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:20:41.074+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:20:41.090+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:20:41.090+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:20:41.101+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.088 seconds
[2022-11-17T19:21:11.371+0000] {processor.py:154} INFO - Started process (PID=204) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:21:11.373+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:21:11.374+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:21:11.374+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:21:11.390+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:21:11.413+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:21:11.413+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:21:11.428+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:21:11.428+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:21:11.439+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.071 seconds
[2022-11-17T19:21:41.718+0000] {processor.py:154} INFO - Started process (PID=235) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:21:41.722+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:21:41.724+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:21:41.724+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:21:41.755+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:21:41.782+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:21:41.782+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:21:41.796+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:21:41.796+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:21:41.808+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.097 seconds
[2022-11-17T19:22:12.079+0000] {processor.py:154} INFO - Started process (PID=265) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:22:12.082+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:22:12.083+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:22:12.083+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:22:12.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:22:12.129+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:22:12.129+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:22:12.145+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:22:12.145+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:22:12.156+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.082 seconds
[2022-11-17T19:22:42.389+0000] {processor.py:154} INFO - Started process (PID=292) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:22:42.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:22:42.399+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:22:42.399+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:22:42.441+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:22:42.482+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:22:42.482+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:22:42.515+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:22:42.515+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:22:42.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.160 seconds
[2022-11-17T19:23:12.878+0000] {processor.py:154} INFO - Started process (PID=316) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:23:12.881+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:23:12.883+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:23:12.883+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:23:12.907+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:23:12.932+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:23:12.931+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:23:12.949+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:23:12.949+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:23:12.962+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.091 seconds
[2022-11-17T19:23:43.256+0000] {processor.py:154} INFO - Started process (PID=346) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:23:43.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:23:43.273+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:23:43.272+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:23:43.288+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:23:43.310+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:23:43.310+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:23:43.324+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:23:43.324+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:23:43.334+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.082 seconds
[2022-11-17T19:24:13.593+0000] {processor.py:154} INFO - Started process (PID=376) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:24:13.595+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:24:13.596+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:24:13.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:24:13.614+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:24:13.636+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:24:13.636+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:24:13.651+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:24:13.650+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:24:13.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.071 seconds
[2022-11-17T19:24:43.961+0000] {processor.py:154} INFO - Started process (PID=405) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:24:43.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:24:43.966+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:24:43.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:24:43.991+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:24:44.018+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:24:44.018+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:24:44.035+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:24:44.035+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:24:44.046+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.092 seconds
[2022-11-17T19:25:14.346+0000] {processor.py:154} INFO - Started process (PID=435) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:25:14.349+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:25:14.350+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:25:14.350+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:25:14.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:25:14.392+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:25:14.392+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:25:14.407+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:25:14.407+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:25:14.419+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.075 seconds
[2022-11-17T19:25:44.738+0000] {processor.py:154} INFO - Started process (PID=456) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:25:44.741+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:25:44.743+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:25:44.743+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:25:44.767+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:25:44.792+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:25:44.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:25:44.806+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:25:44.806+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:25:44.817+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T19:26:15.172+0000] {processor.py:154} INFO - Started process (PID=486) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:26:15.174+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:26:15.177+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:26:15.177+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:26:15.197+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:26:15.221+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:26:15.221+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:26:15.235+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:26:15.235+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:26:15.246+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.078 seconds
[2022-11-17T19:26:45.500+0000] {processor.py:154} INFO - Started process (PID=516) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:26:45.504+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:26:45.506+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:26:45.506+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:26:45.528+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:26:45.563+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:26:45.563+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:26:45.584+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:26:45.584+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:26:45.602+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.104 seconds
[2022-11-17T19:27:15.928+0000] {processor.py:154} INFO - Started process (PID=547) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:27:15.931+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:27:15.932+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:27:15.932+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:27:15.957+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:27:15.983+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:27:15.983+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:27:15.998+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:27:15.997+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:27:16.009+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T19:27:46.296+0000] {processor.py:154} INFO - Started process (PID=577) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:27:46.298+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:27:46.299+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:27:46.299+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:27:46.314+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:27:46.337+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:27:46.337+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:27:46.352+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:27:46.352+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:27:46.363+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.071 seconds
[2022-11-17T19:28:16.681+0000] {processor.py:154} INFO - Started process (PID=608) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:28:16.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:28:16.685+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:28:16.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:28:16.715+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:28:16.753+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:28:16.753+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:28:16.773+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:28:16.773+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:28:16.798+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.120 seconds
[2022-11-17T19:28:47.069+0000] {processor.py:154} INFO - Started process (PID=629) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:28:47.072+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:28:47.074+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:28:47.074+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:28:47.095+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:28:47.135+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:28:47.134+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:28:47.152+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:28:47.152+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:28:47.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.097 seconds
[2022-11-17T19:29:17.381+0000] {processor.py:154} INFO - Started process (PID=657) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:29:17.383+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:29:17.384+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:29:17.384+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:29:17.401+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:29:17.460+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:29:17.460+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:29:17.476+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:29:17.475+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:29:17.488+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.109 seconds
[2022-11-17T19:29:47.706+0000] {processor.py:154} INFO - Started process (PID=686) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:29:47.725+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:29:47.727+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:29:47.727+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:29:47.742+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:29:47.763+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:29:47.763+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:29:47.777+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:29:47.777+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:29:47.788+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T19:30:18.058+0000] {processor.py:154} INFO - Started process (PID=717) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:30:18.059+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:30:18.061+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:30:18.061+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:30:18.078+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:30:18.100+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:30:18.100+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:30:18.113+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:30:18.113+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:30:18.123+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.069 seconds
[2022-11-17T19:30:48.376+0000] {processor.py:154} INFO - Started process (PID=746) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:30:48.378+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:30:48.379+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:30:48.379+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:30:48.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:30:48.424+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:30:48.423+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:30:48.440+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:30:48.440+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:30:48.453+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.079 seconds
[2022-11-17T19:31:18.703+0000] {processor.py:154} INFO - Started process (PID=767) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:31:18.707+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:31:18.710+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:31:18.710+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:31:18.745+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:31:18.769+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:31:18.769+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:31:18.784+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:31:18.784+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:31:18.819+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.123 seconds
[2022-11-17T19:31:49.213+0000] {processor.py:154} INFO - Started process (PID=797) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:31:49.216+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:31:49.220+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:31:49.220+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:31:49.243+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:31:49.269+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:31:49.269+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:31:49.284+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:31:49.284+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:31:49.295+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.087 seconds
[2022-11-17T19:32:19.578+0000] {processor.py:154} INFO - Started process (PID=826) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:32:19.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:32:19.582+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:32:19.582+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:32:19.603+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:32:19.627+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:32:19.627+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:32:19.641+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:32:19.641+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:32:19.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.080 seconds
[2022-11-17T19:32:49.915+0000] {processor.py:154} INFO - Started process (PID=856) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:32:49.919+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:32:49.920+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:32:49.920+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:32:49.947+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:32:49.970+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:32:49.970+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:32:49.985+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:32:49.985+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:32:49.996+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T19:33:20.318+0000] {processor.py:154} INFO - Started process (PID=888) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:33:20.322+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:33:20.323+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:33:20.323+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:33:20.348+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:33:20.373+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:33:20.373+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:33:20.388+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:33:20.388+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:33:20.399+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.087 seconds
[2022-11-17T19:33:50.710+0000] {processor.py:154} INFO - Started process (PID=918) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:33:50.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:33:50.713+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:33:50.713+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:33:50.741+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:33:50.791+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:33:50.790+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:33:50.814+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:33:50.814+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:33:50.834+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.127 seconds
[2022-11-17T19:34:21.232+0000] {processor.py:154} INFO - Started process (PID=939) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:34:21.235+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:34:21.239+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:34:21.239+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:34:21.259+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:34:21.289+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:34:21.289+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:34:21.304+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:34:21.303+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:34:21.314+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T19:34:51.692+0000] {processor.py:154} INFO - Started process (PID=969) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:34:51.694+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:34:51.696+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:34:51.696+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:34:51.719+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:34:51.744+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:34:51.744+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:34:51.758+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:34:51.758+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:34:51.769+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.082 seconds
[2022-11-17T19:35:22.188+0000] {processor.py:154} INFO - Started process (PID=999) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:35:22.191+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:35:22.193+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:35:22.193+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:35:22.218+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:35:22.241+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:35:22.241+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:35:22.256+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:35:22.256+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:35:22.265+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.082 seconds
[2022-11-17T19:35:52.597+0000] {processor.py:154} INFO - Started process (PID=1028) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:35:52.599+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:35:52.601+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:35:52.601+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:35:52.624+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:35:52.649+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:35:52.649+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:35:52.665+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:35:52.664+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:35:52.676+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T19:36:23.007+0000] {processor.py:154} INFO - Started process (PID=1058) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:36:23.010+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:36:23.013+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:36:23.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:36:23.038+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:36:23.063+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:36:23.063+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:36:23.077+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:36:23.077+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:36:23.087+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
[2022-11-17T19:36:53.487+0000] {processor.py:154} INFO - Started process (PID=1088) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:36:53.488+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:36:53.490+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:36:53.490+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:36:53.509+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:36:53.534+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:36:53.534+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:36:53.550+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:36:53.550+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:36:53.565+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.080 seconds
[2022-11-17T19:37:23.924+0000] {processor.py:154} INFO - Started process (PID=1109) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:37:23.927+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:37:23.929+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:37:23.929+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:37:23.952+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:37:23.978+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:37:23.978+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:37:23.992+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:37:23.992+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:37:24.003+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.085 seconds
[2022-11-17T19:39:10.909+0000] {processor.py:154} INFO - Started process (PID=1121) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:39:10.911+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:39:10.913+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:39:10.912+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:39:10.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:39:10.957+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:39:10.957+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:39:10.974+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:39:10.974+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:39:10.988+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T19:46:12.449+0000] {processor.py:154} INFO - Started process (PID=1151) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:46:12.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:46:12.452+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:46:12.452+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:46:12.465+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:46:12.486+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:46:12.486+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:46:12.500+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:46:12.500+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:46:12.511+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.065 seconds
[2022-11-17T19:46:42.810+0000] {processor.py:154} INFO - Started process (PID=1181) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:46:42.812+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T19:46:42.813+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:46:42.813+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:46:42.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T19:46:42.852+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:46:42.852+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T19:46:42.866+0000] {logging_mixin.py:137} INFO - [2022-11-17T19:46:42.866+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T19:46:42.877+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.069 seconds
[2022-11-17T20:02:24.228+0000] {processor.py:154} INFO - Started process (PID=1203) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:02:24.231+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T20:02:24.233+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:02:24.233+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:02:24.279+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:02:24.353+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:02:24.353+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T20:02:24.387+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:02:24.387+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T20:02:24.421+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.196 seconds
[2022-11-17T20:19:07.051+0000] {processor.py:154} INFO - Started process (PID=1233) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:19:07.053+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T20:19:07.054+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:19:07.054+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:19:07.069+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:19:07.094+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:19:07.094+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T20:19:07.109+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:19:07.109+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T20:19:07.121+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.072 seconds
[2022-11-17T20:19:37.469+0000] {processor.py:154} INFO - Started process (PID=1262) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:19:37.472+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T20:19:37.473+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:19:37.473+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:19:37.496+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:19:37.522+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:19:37.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T20:19:37.536+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:19:37.536+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T20:19:37.547+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T20:37:04.195+0000] {processor.py:154} INFO - Started process (PID=1292) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:37:04.199+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T20:37:04.200+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:37:04.200+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:37:04.226+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:37:04.280+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:37:04.280+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T20:37:04.306+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:37:04.306+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T20:37:04.328+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.136 seconds
[2022-11-17T20:53:15.062+0000] {processor.py:154} INFO - Started process (PID=1321) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:53:15.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T20:53:15.065+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:53:15.065+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:53:15.083+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:53:15.113+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:53:15.113+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T20:53:15.130+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:53:15.130+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T20:53:15.142+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.082 seconds
[2022-11-17T20:53:45.515+0000] {processor.py:154} INFO - Started process (PID=1342) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:53:45.518+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T20:53:45.520+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:53:45.520+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:53:45.544+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T20:53:45.569+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:53:45.569+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T20:53:45.586+0000] {logging_mixin.py:137} INFO - [2022-11-17T20:53:45.586+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T20:53:45.601+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.091 seconds
[2022-11-17T21:10:13.050+0000] {processor.py:154} INFO - Started process (PID=1372) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:10:13.052+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T21:10:13.053+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:10:13.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:10:13.070+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:10:13.106+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:10:13.106+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T21:10:13.128+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:10:13.128+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T21:10:13.162+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.116 seconds
[2022-11-17T21:10:43.386+0000] {processor.py:154} INFO - Started process (PID=1401) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:10:43.388+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T21:10:43.390+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:10:43.390+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:10:43.406+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:10:43.429+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:10:43.429+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T21:10:43.443+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:10:43.443+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T21:10:43.453+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.072 seconds
[2022-11-17T21:27:51.056+0000] {processor.py:154} INFO - Started process (PID=1430) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:27:51.057+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T21:27:51.058+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:27:51.058+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:27:51.074+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:27:51.096+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:27:51.096+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T21:27:51.110+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:27:51.110+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T21:27:51.120+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.067 seconds
[2022-11-17T21:28:21.481+0000] {processor.py:154} INFO - Started process (PID=1461) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:28:21.483+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T21:28:21.487+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:28:21.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:28:21.521+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:28:21.568+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:28:21.568+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T21:28:21.586+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:28:21.586+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T21:28:21.617+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.147 seconds
[2022-11-17T21:44:14.821+0000] {processor.py:154} INFO - Started process (PID=1482) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:44:14.825+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T21:44:14.827+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:44:14.827+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:44:14.871+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T21:44:14.921+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:44:14.921+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T21:44:14.955+0000] {logging_mixin.py:137} INFO - [2022-11-17T21:44:14.954+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T21:44:14.985+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.168 seconds
[2022-11-17T22:00:09.506+0000] {processor.py:154} INFO - Started process (PID=1512) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:00:09.508+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T22:00:09.509+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:00:09.509+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:00:09.528+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:00:09.552+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:00:09.552+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T22:00:09.568+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:00:09.568+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T22:00:09.579+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.076 seconds
[2022-11-17T22:00:39.932+0000] {processor.py:154} INFO - Started process (PID=1543) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:00:39.936+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T22:00:39.938+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:00:39.938+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:00:39.959+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:00:39.983+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:00:39.983+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T22:00:39.998+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:00:39.998+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T22:00:40.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.084 seconds
[2022-11-17T22:19:03.404+0000] {processor.py:154} INFO - Started process (PID=1573) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:19:03.408+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T22:19:03.411+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:19:03.411+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:19:03.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:19:03.467+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:19:03.467+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T22:19:03.484+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:19:03.484+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T22:19:03.513+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.116 seconds
[2022-11-17T22:19:33.951+0000] {processor.py:154} INFO - Started process (PID=1593) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:19:33.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T22:19:33.982+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:19:33.982+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:19:34.017+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:19:34.041+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:19:34.041+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T22:19:34.055+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:19:34.055+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T22:19:34.067+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.123 seconds
[2022-11-17T22:36:13.613+0000] {processor.py:154} INFO - Started process (PID=1623) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:36:13.614+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T22:36:13.616+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:36:13.616+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:36:13.652+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:36:13.742+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:36:13.742+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T22:36:13.775+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:36:13.775+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T22:36:13.800+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.193 seconds
[2022-11-17T22:54:09.052+0000] {processor.py:154} INFO - Started process (PID=1652) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:54:09.054+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T22:54:09.056+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:54:09.056+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:54:09.088+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:54:09.142+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:54:09.141+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T22:54:09.173+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:54:09.173+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T22:54:09.195+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.149 seconds
[2022-11-17T22:54:39.512+0000] {processor.py:154} INFO - Started process (PID=1682) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:54:39.513+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T22:54:39.514+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:54:39.514+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:54:39.530+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T22:54:39.553+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:54:39.553+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T22:54:39.568+0000] {logging_mixin.py:137} INFO - [2022-11-17T22:54:39.568+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T22:54:39.578+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.069 seconds
[2022-11-17T23:10:12.130+0000] {processor.py:154} INFO - Started process (PID=1712) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:10:12.132+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T23:10:12.134+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:10:12.134+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:10:12.201+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:10:12.306+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:10:12.306+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T23:10:12.352+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:10:12.352+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T23:10:12.400+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.278 seconds
[2022-11-17T23:10:42.718+0000] {processor.py:154} INFO - Started process (PID=1734) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:10:42.719+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T23:10:42.720+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:10:42.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:10:42.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:10:42.758+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:10:42.758+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T23:10:42.772+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:10:42.772+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T23:10:42.783+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.068 seconds
[2022-11-17T23:28:45.205+0000] {processor.py:154} INFO - Started process (PID=1764) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:28:45.206+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T23:28:45.207+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:28:45.207+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:28:45.221+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:28:45.242+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:28:45.242+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T23:28:45.256+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:28:45.256+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T23:28:45.266+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.065 seconds
[2022-11-17T23:46:02.054+0000] {processor.py:154} INFO - Started process (PID=1792) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:46:02.056+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T23:46:02.058+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:46:02.058+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:46:02.072+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:46:02.096+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:46:02.096+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T23:46:02.110+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:46:02.110+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T23:46:02.121+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.070 seconds
[2022-11-17T23:46:32.440+0000] {processor.py:154} INFO - Started process (PID=1821) to work on /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:46:32.444+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/load_data_to_spark.py for tasks to queue
[2022-11-17T23:46:32.446+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:46:32.446+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:46:32.471+0000] {processor.py:766} INFO - DAG(s) dict_keys(['spark_operator']) retrieved from /opt/airflow/dags/load_data_to_spark.py
[2022-11-17T23:46:32.496+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:46:32.496+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-17T23:46:32.510+0000] {logging_mixin.py:137} INFO - [2022-11-17T23:46:32.510+0000] {dag.py:3340} INFO - Setting next_dagrun for spark_operator to 2022-11-17T00:00:00+00:00, run_after=2022-11-18T00:00:00+00:00
[2022-11-17T23:46:32.521+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/load_data_to_spark.py took 0.086 seconds
